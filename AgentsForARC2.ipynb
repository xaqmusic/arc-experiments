{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8538f9b-3ef4-461d-97b3-c9ffeccadf01",
   "metadata": {},
   "source": [
    "# 3x3 SimpleAgents Working on ARC Puzzles POC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf79bb-05f5-4455-8122-edcfed93c737",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "This code is designed to solve ARC (AI Research Challenge) puzzles using a neural network-based approach. The main components of the code include:\n",
    "\n",
    "1. **SimpleAgent Class**: This is a neural network model defined using PyTorch's `nn.Module`. It consists of three fully connected layers with ReLU activations and outputs a log-softmax distribution over 10 classes. The input size is 18, which likely includes both grid data and an epoch value.\n",
    "\n",
    "2. **distribute_agents Function**: This function generates a list of agent positions across the grid based on the specified `grid_size` and `agent_scope`.\n",
    "\n",
    "3. **train_agents Function**: This function trains multiple simple agents distributed over the grid. It uses Mean Squared Error (MSE) loss for optimization, with an Adam optimizer. The training process involves:\n",
    "   - Moving models to the specified device (e.g., GPU).\n",
    "   - Collecting predictions from each agent based on their local grid area.\n",
    "   - Calculating loss for each prediction and updating the model parameters.\n",
    "   - Adjusting the learning rate dynamically based on the decrease in training loss.\n",
    "\n",
    "4. **update_plots Function**: This function updates the visualization plots during training, including the loss plot and the grid transformation visualization. It saves these plots to specified directories.\n",
    "\n",
    "5. **transform_grid Function**: This function transforms the input grid using the trained agents' predictions for each position on the grid.\n",
    "\n",
    "6. **save_initial_grid Function**: This function saves an initial grid image before starting the training process.\n",
    "\n",
    "7. **load_arc_data Function**: This function loads ARC JSON data, converting it into tensors suitable for training.\n",
    "\n",
    "8. **Main Script**: The main part of the script initializes plots, loads ARC data, creates and trains agents, and transforms the input grid based on the trained models' predictions. It also saves initial grids and transformed grids for visualization and debugging purposes.\n",
    "\n",
    "### Key Points:\n",
    "- **Distributed Agents**: Each agent is responsible for a local area on the grid and makes predictions based on its local context.\n",
    "- **Dynamic Learning Rate Adjustment**: The learning rate is adjusted dynamically during training to improve convergence.\n",
    "- **Visualization and Debugging**: Extensive plotting and saving of intermediate results allow for easy visualization and debugging throughout the training process.\n",
    "- **Training Process**: The agents are trained iteratively over multiple epochs, with loss being monitored and plotted to assess model performance.\n",
    "\n",
    "Author's note: This code is designed as a starting point for grokking the necessary components required for solving ARC and similar problems.  This approach was not expected to work.  However, completing the basic functionality as inteded lent me a wealth of knowledge for more promising approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46c9c8-8fca-462c-b4df-23c25d96b983",
   "metadata": {},
   "source": [
    "# v0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5792f652-53a2-4231-9867-389305486ad0",
   "metadata": {},
   "source": [
    "## Training Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d07c6-e314-44f2-bf7d-d9f1d0031b00",
   "metadata": {},
   "source": [
    "NOTES:  This embodiment took about 12.5 hours to train on my RTX 4060ti / AMD 3700 Windows PC (notebook running in WSL).  The smallest grid in this example required 4 seconds per epoch while the last and largest grid required over a minute per epoch.  Basically, this is the worlds fanciest random number generator :-P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00195359-da8c-4b04-968d-0e46542ef7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Grid after Epoch 700:\n",
      "[[0. 0. 0. 1. 9. 0. 0. 0. 0. 0. 3. 2. 6. 5. 5. 4. 1. 4. 8. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 4. 3. 0. 0. 2. 0. 0. 9. 5. 7. 1. 0. 2. 2.]\n",
      " [1. 0. 2. 7. 0. 4. 1. 0. 0. 7. 1. 0. 9. 2. 3. 7. 5. 9. 7. 2.]\n",
      " [0. 0. 0. 8. 0. 1. 0. 1. 0. 0. 3. 3. 0. 7. 7. 6. 1. 2. 3. 2.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 7. 7. 0. 1. 0. 9. 0. 8. 4.]\n",
      " [0. 5. 0. 1. 0. 0. 0. 0. 0. 0. 6. 2. 2. 7. 4. 0. 6. 2. 2. 2.]\n",
      " [3. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 8. 4. 1. 7. 7. 1. 2. 2. 7.]\n",
      " [0. 0. 1. 4. 0. 0. 0. 0. 0. 5. 0. 2. 9. 8. 5. 9. 2. 8. 0. 5.]\n",
      " [0. 2. 8. 0. 0. 1. 0. 1. 0. 0. 8. 6. 9. 0. 3. 0. 7. 4. 9. 9.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 7. 9. 1. 5. 5. 6. 0. 6. 9. 5. 2. 3. 7.]\n",
      " [3. 8. 4. 8. 6. 2. 2. 1. 4. 0. 1. 7. 1. 3. 2. 2. 8. 8. 0. 0.]\n",
      " [0. 8. 7. 7. 0. 3. 7. 7. 8. 2. 1. 9. 5. 5. 7. 2. 3. 5. 4. 3.]\n",
      " [2. 4. 6. 4. 0. 4. 3. 2. 7. 0. 8. 6. 9. 6. 3. 0. 4. 5. 2. 8.]\n",
      " [3. 0. 5. 8. 4. 9. 1. 8. 4. 3. 0. 2. 9. 4. 0. 9. 5. 4. 3. 6.]\n",
      " [5. 8. 1. 2. 0. 4. 0. 0. 0. 9. 8. 7. 9. 3. 6. 0. 3. 1. 6. 6.]\n",
      " [6. 7. 4. 5. 0. 8. 8. 8. 0. 0. 1. 7. 3. 7. 9. 0. 0. 0. 1. 6.]\n",
      " [0. 0. 2. 8. 9. 6. 6. 2. 1. 0. 2. 6. 8. 2. 0. 1. 0. 0. 3. 5.]\n",
      " [5. 5. 4. 8. 6. 3. 0. 3. 3. 3. 1. 5. 5. 4. 6. 8. 4. 6. 5. 0.]\n",
      " [1. 7. 9. 8. 3. 2. 6. 7. 6. 9. 9. 3. 8. 0. 3. 7. 1. 7. 3. 0.]\n",
      " [9. 8. 4. 1. 2. 0. 8. 2. 8. 3. 5. 5. 0. 2. 6. 0. 0. 7. 6. 5.]]\n",
      "Epoch 700, Training Loss: 7434.0266, Validation Loss: 7434.0265\n",
      "\n",
      "New Learning Rate:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transforming Grid...\n",
      "\n",
      "Input Grid:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 3. 3. 3. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 3. 0. 0. 0. 0. 0. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 0. 0. 0. 0. 3. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 3. 3. 0. 0. 3. 0. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 3. 0. 3. 0. 0. 3. 3. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 3. 3. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Output Grid after Transformation (Desired):\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 3. 3. 3. 4. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 4. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 4. 4. 4. 4. 4. 4. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 0. 0. 0. 3. 4. 4. 4. 4. 4. 4. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 4. 4. 4. 4. 4. 4. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 4. 4. 4. 4. 4. 4. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 3. 0. 0. 0. 0. 0. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 0. 0. 0. 0. 3. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 3. 3. 4. 4. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 3. 4. 4. 3. 3. 0. 0. 3. 0. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 3. 0. 3. 0. 0. 3. 3. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 4. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 3. 3. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Output Grid after Transformation (Model's Prediction):\n",
      "[[0. 0. 0. 1. 7. 0. 0. 0. 0. 0. 9. 3. 7. 9. 1. 5. 3. 0. 6. 5.]\n",
      " [2. 0. 0. 0. 0. 0. 5. 3. 0. 0. 5. 9. 9. 5. 3. 9. 1. 7. 8. 2.]\n",
      " [1. 2. 2. 0. 0. 6. 1. 0. 0. 0. 6. 3. 9. 0. 5. 1. 7. 6. 4. 1.]\n",
      " [0. 0. 0. 2. 0. 1. 0. 1. 0. 0. 5. 3. 0. 8. 7. 0. 4. 7. 6. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 8. 1. 0. 2. 6. 8. 8. 4. 3.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 4. 0. 6. 5. 6. 8. 3. 9. 4.]\n",
      " [0. 0. 0. 0. 3. 0. 1. 1. 0. 0. 4. 9. 6. 0. 9. 2. 8. 5. 8. 7.]\n",
      " [0. 0. 1. 6. 0. 0. 0. 0. 0. 1. 0. 5. 5. 6. 3. 7. 7. 0. 4. 5.]\n",
      " [0. 2. 2. 0. 0. 1. 0. 1. 0. 0. 8. 7. 7. 9. 3. 0. 0. 0. 4. 4.]\n",
      " [0. 0. 0. 0. 0. 2. 1. 7. 9. 1. 6. 3. 8. 6. 0. 0. 7. 3. 8. 4.]\n",
      " [6. 0. 5. 8. 8. 0. 3. 3. 6. 0. 6. 6. 6. 8. 2. 9. 6. 7. 4. 2.]\n",
      " [7. 2. 2. 8. 2. 2. 6. 2. 8. 2. 9. 6. 4. 1. 7. 5. 8. 7. 5. 8.]\n",
      " [2. 7. 3. 4. 5. 8. 3. 0. 3. 0. 1. 7. 2. 8. 8. 0. 3. 6. 7. 9.]\n",
      " [3. 9. 7. 4. 5. 8. 5. 2. 3. 3. 8. 0. 2. 2. 8. 0. 1. 1. 4. 9.]\n",
      " [2. 4. 9. 2. 5. 7. 2. 9. 0. 3. 7. 8. 9. 3. 2. 0. 1. 1. 2. 5.]\n",
      " [8. 3. 6. 4. 5. 2. 8. 4. 0. 4. 3. 8. 3. 6. 5. 0. 9. 3. 2. 2.]\n",
      " [0. 9. 2. 7. 5. 6. 7. 5. 8. 1. 5. 5. 9. 8. 6. 2. 0. 2. 5. 2.]\n",
      " [9. 5. 3. 2. 0. 8. 3. 9. 8. 1. 6. 7. 4. 0. 5. 4. 0. 1. 1. 7.]\n",
      " [5. 0. 7. 8. 8. 0. 3. 5. 9. 1. 8. 4. 8. 2. 5. 5. 3. 7. 5. 9.]\n",
      " [8. 6. 1. 4. 2. 6. 2. 7. 2. 1. 5. 1. 8. 7. 8. 4. 8. 3. 7. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "# ************************ set initial learning rate here\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=4, learning_rate=0.01, device='cuda', plot_dir=None, model_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Normalize the epoch\n",
    "                normalized_epoch = float(epoch) / epochs\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase\n",
    "        validation_loss = 0\n",
    "\n",
    "        # Initialize transformed grid with zeros for consistency\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0], dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "                simple_predictions = []\n",
    "\n",
    "                # Collect predictions from simple agents\n",
    "                for position, model in simple_agent_models.items():\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(x.size(0), position[0] + 3)\n",
    "                    y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                    local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "\n",
    "                    if len(local_x) != 9:\n",
    "                        local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "\n",
    "                    # Normalize epoch\n",
    "                    normalized_epoch = float(epoch) / epochs\n",
    "\n",
    "                    # Add epoch to the input\n",
    "                    local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "\n",
    "                    # Forward pass for the current simple agent\n",
    "                    prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                    \n",
    "                    # Append the prediction (logits) to the list (ensure it's on CPU)\n",
    "                    simple_predictions.append(prediction.squeeze().cpu())\n",
    "\n",
    "                combined_pred = torch.stack(simple_predictions)\n",
    "\n",
    "                # Prepare target values for each prediction (validation phase)\n",
    "                y_flat = y.flatten().long().to(device)\n",
    "                simple_targets = []\n",
    "\n",
    "                for position in simple_agent_models:\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(y.size(0), position[0] + 3)\n",
    "                    y_end = min(y.size(1), position[1] + 3)\n",
    "\n",
    "                    local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "\n",
    "                    if len(local_y) != 9:\n",
    "                        local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "\n",
    "                    # Convert to long and append the target\n",
    "                    simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "\n",
    "                all_targets = torch.stack(simple_targets)\n",
    "\n",
    "                # Calculate validation loss for each prediction separately\n",
    "                total_validation_loss_this_sample = 0\n",
    "\n",
    "                for pred, target in zip(combined_pred, all_targets):\n",
    "                    if pred.numel() == 0 or target.numel() == 0:\n",
    "                        raise ValueError(f\"Zero-sized tensor encountered. pred shape: {pred.shape}, target shape: {target.shape}\")\n",
    "                    \n",
    "                    # Ensure the target is a LongTensor for CrossEntropyLoss\n",
    "                    loss = criterion(pred.unsqueeze(0), target.long().unsqueeze(0))\n",
    "                    total_validation_loss_this_sample += loss.item()\n",
    "\n",
    "                validation_loss += total_validation_loss_this_sample\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "\n",
    "        # Update transformed grid based on predictions (if needed)\n",
    "        for j, position in enumerate(simple_agents):\n",
    "            prediction = combined_pred[j].argmax(dim=0).item()\n",
    "            transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "        \n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, epoch=epoch, device=device)\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        if average_loss < 0.000001 and average_validation_loss < 0.000001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # ***********  Adjust the learning rate as loss decreases\n",
    "        initial_lr = optimizer.param_groups[0]['lr']\n",
    "        max_epoch = epochs\n",
    "        k = 0.5  # higher value will make transition to lower rate toward end of training steeper (0.1 to 0.9)\n",
    "        min_lr = 0.001  # Minimum learning rate\n",
    "        new_lr = initial_lr\n",
    "        decay_factor = 0\n",
    "        if epoch > 0 and losses[-1] < losses[-2]:\n",
    "            # Calculate the decay factor using a sigmoid function\n",
    "            decay_factor = 1 / (1 + math.exp(-k * (epoch - max_epoch / 2)))\n",
    "            new_lr = initial_lr * (1 - decay_factor)\n",
    "            # Ensure the learning rate does not decrease below the minimum threshold\n",
    "            if new_lr > min_lr:\n",
    "                optimizer.param_groups[0]['lr'] = new_lr\n",
    "                print(f\"Reducing learning rate from {initial_lr} to {new_lr}\")\n",
    "            else:\n",
    "                print(f\"Learning rate would have decreased to {new_lr}, but it has been set to the minimum threshold of {min_lr}.\")\n",
    "                optimizer.param_groups[0]['lr'] = min_lr\n",
    "                new_lr = min_lr\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "        print(f\"\\nNew Learning Rate:{new_lr}\")\n",
    "    \n",
    "    # Save the model after training\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Saved model at position {position} to {model_path}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='inferno', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # ******** Save only the grid plot without colorbar\n",
    "    # fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    # cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    # ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    # fig2.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    # plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    # initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    initial_grid = grid\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='inferno', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory and model directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                model = SimpleAgent()\n",
    "            simple_agent_models[position] = model\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        initial_grid = input_grid\n",
    "        print(f\"\\nInitial Grid:\\n{initial_grid}\")\n",
    "        \n",
    "        train_inputs = [initial_grid]\n",
    "        # train_inputs = [input_grid.to(device)]\n",
    "        print(f\"\\nInput Grid:\\n{train_inputs}\")\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        print(f\"\\nOutput Grid:\\n{train_outputs}\")\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=700, device=device, plot_dir=plot_dir, model_dir=model_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, epoch=0, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d55ca-ef3c-4339-9098-e4899ac71557",
   "metadata": {},
   "source": [
    "# Inference Runner for Current Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858235b2-4e43-4670-b1ab-f708ca1ccdd0",
   "metadata": {},
   "source": [
    "If you change the model definition (layers etc) during training, be sure it is also changes here.  Otherwise the model will not load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5a3c4e2-53ed-4213-9918-d8efcdd845cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Grid after Inference:\n",
      "[[0. 0. 0. 1. 9. 0. 0. 0. 0. 0. 3. 2. 6. 5. 5. 4. 1. 6. 8. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 4. 3. 0. 0. 2. 0. 0. 9. 5. 7. 1. 0. 2. 2.]\n",
      " [1. 0. 2. 7. 0. 4. 1. 0. 0. 7. 1. 0. 9. 2. 3. 7. 5. 9. 7. 2.]\n",
      " [0. 0. 0. 8. 0. 1. 0. 1. 0. 0. 3. 3. 0. 7. 7. 6. 1. 2. 3. 2.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 7. 6. 0. 1. 0. 9. 0. 8. 4.]\n",
      " [0. 5. 0. 1. 0. 0. 0. 0. 0. 0. 6. 2. 2. 7. 4. 0. 6. 2. 2. 2.]\n",
      " [3. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 8. 4. 1. 7. 7. 0. 2. 2. 7.]\n",
      " [0. 0. 1. 4. 0. 0. 0. 0. 0. 5. 0. 2. 9. 6. 5. 9. 2. 7. 0. 5.]\n",
      " [0. 2. 8. 0. 0. 1. 0. 1. 0. 0. 8. 6. 9. 0. 3. 0. 7. 4. 9. 9.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 7. 9. 1. 5. 5. 6. 0. 6. 9. 5. 2. 8. 7.]\n",
      " [3. 8. 4. 8. 6. 2. 2. 1. 4. 0. 1. 7. 1. 3. 2. 2. 8. 8. 0. 0.]\n",
      " [0. 8. 7. 7. 0. 3. 7. 7. 8. 2. 1. 9. 5. 5. 7. 2. 3. 5. 4. 3.]\n",
      " [2. 4. 6. 4. 0. 4. 3. 2. 7. 0. 8. 6. 9. 6. 3. 0. 4. 9. 2. 8.]\n",
      " [3. 0. 5. 8. 4. 9. 1. 8. 4. 3. 0. 2. 9. 4. 0. 9. 5. 4. 3. 6.]\n",
      " [5. 8. 1. 0. 0. 4. 0. 0. 0. 9. 8. 7. 9. 3. 6. 0. 3. 1. 6. 6.]\n",
      " [6. 7. 0. 5. 0. 8. 8. 8. 0. 0. 1. 7. 3. 7. 9. 0. 0. 0. 1. 6.]\n",
      " [0. 0. 2. 8. 9. 6. 6. 2. 1. 0. 2. 6. 8. 2. 0. 1. 0. 0. 3. 4.]\n",
      " [5. 5. 4. 8. 6. 3. 0. 3. 3. 1. 1. 5. 5. 4. 6. 8. 4. 6. 5. 0.]\n",
      " [1. 7. 9. 8. 3. 2. 6. 7. 6. 9. 9. 3. 8. 0. 3. 7. 1. 7. 3. 0.]\n",
      " [9. 8. 4. 1. 2. 0. 8. 2. 8. 3. 5. 5. 0. 2. 6. 0. 0. 7. 6. 5.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.zeros_like(grid)  # Initialize with zeros\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Create the input for the model\n",
    "        epoch_tensor = torch.tensor([epoch], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        input_to_model = torch.cat((local_area_tensor.unsqueeze(0), epoch_tensor), dim=1)\n",
    "        \n",
    "        # Forward pass for the current simple agent if it exists\n",
    "        if position in simple_agent_models:\n",
    "            with torch.no_grad():  # Disable gradient computation during inference\n",
    "                prediction = simple_agent_models[position](input_to_model.to(device)).argmax(dim=1).item()  # Ensure input is on device\n",
    "            \n",
    "            transformed[position[0]][position[1]] = prediction\n",
    "        else:\n",
    "            print(f\"Warning: No model found for agent at position {position}. Skipping.\")\n",
    "            \n",
    "    return torch.tensor(transformed, dtype=torch.float32).to(device)\n",
    "\n",
    "def update_plots_inference(fig, ax1, epoch, current_grid, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "\n",
    "    # Move the tensor to CPU and then convert it to a numpy array\n",
    "    current_grid_cpu = current_grid.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax1.imshow(current_grid_cpu, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax1.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "\n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the inference plot directory and model directory\n",
    "inf_plot_dir = '/home/xaqmusic/inf_plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(inf_plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig_inference, ax_inference = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Loading agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        global simple_agent_models\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "                model.eval()  # Set the model to evaluation mode\n",
    "                simple_agent_models[position] = model.to(device)  # Ensure the model is on the correct device\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Initialize the grid for inference with the input grid or random\n",
    "        # current_grid = input_grid.clone().to(device)\n",
    "        current_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        \n",
    "        print(\"Running Inference...\")\n",
    "        for epoch in tqdm(range(100), desc=\"Inference\", leave=False):\n",
    "            current_grid = transform_grid(current_grid.cpu(), simple_agents, epoch=epoch, device=device)\n",
    "            update_plots_inference(fig_inference, ax_inference, epoch + 1, current_grid, inf_plot_dir)\n",
    "            clear_output(wait=True)\n",
    "            # print(current_grid)\n",
    "        print(\"\\nFinal Grid after Inference:\")\n",
    "        print(current_grid.cpu().numpy())\n",
    "        # input('Press Enter to Continue to Next Grid')\n",
    "\n",
    "# Close the inference figure to free up memory\n",
    "plt.close(fig_inference)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
