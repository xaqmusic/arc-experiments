{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f5c51e-4228-40e1-9602-d7a695e93e0a",
   "metadata": {},
   "source": [
    "/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json\n",
    "\n",
    "Things to fix:  Agents need to cover entire grid and be able to transform their section into ints 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d59c28-e74f-45b2-b878-57cdf4cbc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))  # Output between 0 and 1\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    for i in range(0, grid_size[0], agent_scope):\n",
    "        for j in range(0, grid_size[1], agent_scope):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, agents, inputs, outputs, epochs=100, learning_rate=0.01, device='cuda', plot_dir=None):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for i, (position, model) in enumerate(zip(agents, agent_models)):\n",
    "        model.to(device)\n",
    "        print(f\"Agent at position {position} moved to {device}\")\n",
    "    \n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in zip(agents, agent_models) for param in model.parameters()]\n",
    "    print(\"Parameters to optimize:\", params_to_optimize)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            agent_inputs = []\n",
    "            predictions = []\n",
    "            \n",
    "            for position, model in zip(agents, agent_models):\n",
    "                x_start = max(0, position[0] - 1)\n",
    "                y_start = max(0, position[1] - 1)\n",
    "                x_end = min(x.size(0), position[0] + 2)\n",
    "                y_end = min(x.size(1), position[1] + 2)\n",
    "              \n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten()\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                agent_inputs.append(local_x)\n",
    "                \n",
    "                # Forward pass for the current agent\n",
    "                prediction = model(agent_inputs[-1].unsqueeze(0).to(device))\n",
    "                print(f\"Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                predictions.append(prediction.squeeze())\n",
    "            \n",
    "            combined_pred = torch.mean(torch.stack(predictions))\n",
    "            \n",
    "            # Use .clone().detach() to avoid issues with tensor conversion\n",
    "            target_value = y[position[0], position[1]].clone().detach().to(device)\n",
    "            loss = criterion(combined_pred, target_value.float())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(input_grid, agents, agent_models_by_position, device=device)\n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}')\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, agents, agent_models_by_position, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position, model in zip(agents, agent_models):\n",
    "        x_start = max(0, position[0] - 1)\n",
    "        y_start = max(0, position[1] - 1)\n",
    "        x_end = min(len(transformed), position[0] + 2)\n",
    "        y_end = min(len(transformed[0]), position[1] + 2)\n",
    "        \n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = model(local_area_tensor.unsqueeze(0)).cpu().item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        if prediction > 0.5:\n",
    "            transformed[position[0]][position[1]] = 4\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "# Function to load ARC JSON data\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = np.array(task['input'])\n",
    "        output_grid = np.array(task['output'])\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = np.array(inputs[i])\n",
    "        output_grid = np.array(outputs[i])\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_agents = len(agents)\n",
    "        agent_models = [SimpleAgent() for _ in range(num_agents)]\n",
    "        \n",
    "        print(\"Mapping each model to its corresponding position\")\n",
    "        agent_position_to_model_idx = {agent: idx for idx, agent in enumerate(agents)}\n",
    "        agent_models_by_position = {agent: agent_models[idx] for idx, agent in enumerate(agents)}\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        train_inputs = [torch.tensor(input_grid, dtype=torch.float32).to(device)]\n",
    "        train_outputs = [torch.tensor(output_grid, dtype=torch.float32).to(device)]\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, agents, train_inputs, train_outputs, epochs=100, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid, agents, agent_models_by_position, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e80ad-3218-451d-b8a9-7266b945eb08",
   "metadata": {},
   "source": [
    "Still not working.  The transformed grids are not changing for each epoch during the validation step and the network is not yet learning the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e44f3-1370-42e8-932c-35bd35fba5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "class ComplexAgent(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ComplexAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    for i in range(0, grid_size[0], agent_scope):\n",
    "        for j in range(0, grid_size[1], agent_scope):\n",
    "            if i + agent_scope <= grid_size[0] and j + agent_scope <= grid_size[1]:\n",
    "                agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agents, complex_agent, inputs, outputs, epochs=100, learning_rate=0.01, device='cuda', plot_dir=None):\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position in simple_agents:\n",
    "        model = simple_agent_models[position]\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "    complex_agent.to(device)\n",
    "    print(f\"Complex Agent moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()] + list(complex_agent.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            simple_targets = []  # Reset simple targets\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local input and flatten\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Ensure local_x_batched has the correct shape (1, 9)\n",
    "                local_x_batched = local_x.view(1, -1)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                model = simple_agent_models[position]\n",
    "                prediction = model(local_x_batched)\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            complex_prediction = complex_agent(x.flatten().unsqueeze(0).to(device)).squeeze()\n",
    "            \n",
    "            # Combine predictions\n",
    "            combined_pred = torch.stack(simple_predictions + [complex_prediction.cpu()])\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            complex_target = y_flat[-1]  # Assuming the last element is the target for the complex agent\n",
    "            \n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local target and flatten\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Ensure local_y_batched has the correct shape (1, 9)\n",
    "                local_y_batched = local_y.view(1, -1)\n",
    "                \n",
    "                # Check if local_y_batched is empty\n",
    "                if local_y_batched.shape[1] != 9:\n",
    "                    print(f\"Error: local_y_batched has an unexpected shape {local_y_batched.shape} for position {position}\")\n",
    "                    continue\n",
    "                \n",
    "                # Use argmax on the batch dimension to get the target class\n",
    "                simple_target = local_y_batched.argmax(dim=1).cpu()\n",
    "                \n",
    "                # Append the target to the list (ensure it's a scalar)\n",
    "                if len(simple_target) == 0:\n",
    "                    print(f\"Warning: Simple Agent at position {position} has an empty target tensor.\")\n",
    "                    continue\n",
    "                \n",
    "                simple_targets.append(simple_target.item())\n",
    "            \n",
    "            # Check if we have valid targets for all simple agents\n",
    "            if len(simple_targets) != len(simple_agents):\n",
    "                print(\"Skipping this sample due to mismatched number of simple targets\")\n",
    "                continue\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.tensor(simple_targets + [complex_target], dtype=torch.long)\n",
    "            print(f\"All Targets shape: {all_targets.shape}\")\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase\n",
    "        validation_loss = 0\n",
    "        transformed_grid = np.zeros_like(inputs[0].cpu().numpy())\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            simple_targets = []  # Reset simple targets\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local input and flatten\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Ensure local_x_batched has the correct shape (1, 9)\n",
    "                local_x_batched = local_x.view(1, -1)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                model = simple_agent_models[position]\n",
    "                prediction = model(local_x_batched)\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            complex_prediction = complex_agent(x.flatten().unsqueeze(0).to(device)).squeeze()\n",
    "            \n",
    "            # Combine predictions\n",
    "            combined_pred = torch.stack(simple_predictions + [complex_prediction.cpu()])\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            complex_target = y_flat[-1]  # Assuming the last element is the target for the complex agent\n",
    "            \n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local target and flatten\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Ensure local_y_batched has the correct shape (1, 9)\n",
    "                local_y_batched = local_y.view(1, -1)\n",
    "                \n",
    "                # Check if local_y_batched is empty\n",
    "                if local_y_batched.shape[1] != 9:\n",
    "                    print(f\"Error: local_y_batched has an unexpected shape {local_y_batched.shape} for position {position}\")\n",
    "                    continue\n",
    "                \n",
    "                # Use argmax on the batch dimension to get the target class\n",
    "                simple_target = local_y_batched.argmax(dim=1).cpu()\n",
    "                \n",
    "                # Append the target to the list (ensure it's a scalar)\n",
    "                if len(simple_target) == 0:\n",
    "                    print(f\"Warning: Simple Agent at position {position} has an empty target tensor.\")\n",
    "                    continue\n",
    "                \n",
    "                simple_targets.append(simple_target.item())\n",
    "            \n",
    "            # Check if we have valid targets for all simple agents\n",
    "            if len(simple_targets) != len(simple_agents):\n",
    "                print(\"Skipping this sample due to mismatched number of simple targets\")\n",
    "                continue\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.tensor(simple_targets + [complex_target], dtype=torch.long)\n",
    "            print(f\"All Targets shape: {all_targets.shape}\")\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for position, pred in zip(simple_agents, simple_predictions):\n",
    "                if pred.argmax(dim=0) == 4:\n",
    "                    transformed_grid[position[0]][position[1]] = 4\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(input_grid, simple_agents, complex_agent, device=device)\n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, complex_agent, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        # Pad the local area if necessary\n",
    "        if len(local_area) != 9:\n",
    "            print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](local_area_tensor.view(1, -1)).cpu().argmax(dim=1).item()  # Add batch dimension\n",
    "        \n",
    "        if prediction == 4:\n",
    "            transformed[position[0]][position[1]] = 4\n",
    "            \n",
    "    complex_prediction = complex_agent(grid_tensor.view(-1).unsqueeze(0)).cpu().argmax(dim=1).item()\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "# Function to load ARC JSON data\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = np.array(task['input'])\n",
    "        output_grid = np.array(task['output'])\n",
    "        \n",
    "        # Print the input and desired output grids\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid)\n",
    "        print(\"\\nDesired Output Grid:\")\n",
    "        print(output_grid)\n",
    "        \n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = np.array(inputs[i])\n",
    "        output_grid = np.array(outputs[i])\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        complex_agent = ComplexAgent(input_size=grid_size[0] * grid_size[1])\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        train_inputs = [torch.tensor(input_grid, dtype=torch.float32).to(device)]\n",
    "        train_outputs = [torch.tensor(output_grid, dtype=torch.long).to(device)]\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agents, complex_agent, train_inputs, train_outputs, epochs=100, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid, simple_agents, complex_agent, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41793542-6117-4783-86a3-7bbf7d60e843",
   "metadata": {},
   "source": [
    "the simple agents are too far apart so they are only updating based on blank pixels.  The boundries are not being addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb76246-c9da-43b8-92d1-faf1642bed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime  # Import datetime to generate timestamp\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(64, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "class ComplexAgent(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ComplexAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    for i in range(0, grid_size[0], agent_scope):\n",
    "        for j in range(0, grid_size[1], agent_scope):\n",
    "            if i + agent_scope <= grid_size[0] and j + agent_scope <= grid_size[1]:\n",
    "                agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def custom_loss(predicted_grid, target_grid, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Calculate a custom loss that rewards grids which are closer in terms of patterns.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicted_grid: The grid generated by the model (numpy array).\n",
    "    - target_grid: The desired output grid (numpy array).\n",
    "    - threshold: A value between 0 and 1 to determine how similar two values need to be.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: The calculated loss.\n",
    "    \"\"\"\n",
    "    # Convert grids to numpy arrays if they are not already\n",
    "    predicted_grid = np.array(predicted_grid)\n",
    "    target_grid = np.array(target_grid)\n",
    "    \n",
    "    # Ensure both grids have the same shape\n",
    "    assert predicted_grid.shape == target_grid.shape, \"Grids must have the same shape\"\n",
    "    \n",
    "    # Calculate the absolute difference between the two grids\n",
    "    diff = np.abs(predicted_grid - target_grid)\n",
    "    \n",
    "    # Count how many cells are within the threshold of being correct\n",
    "    within_threshold_count = np.sum(diff < threshold)\n",
    "    \n",
    "    # Calculate the custom loss as the percentage of cells not within the threshold\n",
    "    loss = 1.0 - (within_threshold_count / predicted_grid.size)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agents, complex_agent, inputs, outputs, epochs=100, learning_rate=0.001, device='cuda', plot_dir=None):\n",
    "    criterion = nn.CrossEntropyLoss()  # Use Cross-Entropy Loss for classification\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position in simple_agents:\n",
    "        model = simple_agent_models[position]\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "    complex_agent.to(device)\n",
    "    print(f\"Complex Agent moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()] + list(complex_agent.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience = 10  # Number of epochs to wait for improvement\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            simple_targets = []  # Initialize this list for targets within the current training sample\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local input and flatten\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Ensure local_x_batched has the correct shape (1, 9)\n",
    "                local_x_batched = local_x.view(1, -1)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                model = simple_agent_models[position]\n",
    "                prediction = model(local_x_batched)\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            complex_prediction = complex_agent(x.flatten().unsqueeze(0).to(device)).squeeze()\n",
    "            \n",
    "            # Combine predictions\n",
    "            combined_pred = torch.stack(simple_predictions + [complex_prediction.cpu()])\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            complex_target = y_flat[-1]  # Assuming the last element is the target for the complex agent\n",
    "            \n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local target and flatten\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Ensure local_y_batched has the correct shape (1, 9)\n",
    "                local_y_batched = local_y.view(1, -1)\n",
    "                \n",
    "                # Check if local_y_batched is empty\n",
    "                if local_y_batched.shape[1] != 9:\n",
    "                    print(f\"Error: local_y_batched has an unexpected shape {local_y_batched.shape} for position {position}\")\n",
    "                    continue\n",
    "                \n",
    "                # Use argmax on the batch dimension to get the target class\n",
    "                simple_target = local_y_batched.argmax(dim=1).cpu()\n",
    "                \n",
    "                # Append the target to the list (ensure it's a scalar)\n",
    "                if len(simple_target) == 0:\n",
    "                    print(f\"Warning: Simple Agent at position {position} has an empty target tensor.\")\n",
    "                    continue\n",
    "                \n",
    "                simple_targets.append(simple_target.item())\n",
    "            \n",
    "            # Check if we have valid targets for all simple agents\n",
    "            if len(simple_targets) != len(simple_agents):\n",
    "                print(\"Skipping this sample due to mismatched number of simple targets\")\n",
    "                continue\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.tensor(simple_targets + [complex_target], dtype=torch.long)\n",
    "            print(f\"All Targets shape: {all_targets.shape}\")\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase\n",
    "        validation_loss = 0\n",
    "        transformed_grid = np.zeros_like(inputs[0].cpu().numpy())\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            simple_targets = []  # Initialize this list for targets within the current validation sample\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local input and flatten\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Ensure local_x_batched has the correct shape (1, 9)\n",
    "                local_x_batched = local_x.view(1, -1)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                model = simple_agent_models[position]\n",
    "                prediction = model(local_x_batched)\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            complex_prediction = complex_agent(x.flatten().unsqueeze(0).to(device)).squeeze()\n",
    "            \n",
    "            # Combine predictions\n",
    "            combined_pred = torch.stack(simple_predictions + [complex_prediction.cpu()])\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            complex_target = y_flat[-1]  # Assuming the last element is the target for the complex agent\n",
    "            \n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                # Extract local target and flatten\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                # Pad the local area if necessary to ensure it's of size 9\n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Ensure local_y_batched has the correct shape (1, 9)\n",
    "                local_y_batched = local_y.view(1, -1)\n",
    "                \n",
    "                # Check if local_y_batched is empty\n",
    "                if local_y_batched.shape[1] != 9:\n",
    "                    print(f\"Error: local_y_batched has an unexpected shape {local_y_batched.shape} for position {position}\")\n",
    "                    continue\n",
    "                \n",
    "                # Use argmax on the batch dimension to get the target class\n",
    "                simple_target = local_y_batched.argmax(dim=1).cpu()\n",
    "                \n",
    "                # Append the target to the list (ensure it's a scalar)\n",
    "                if len(simple_target) == 0:\n",
    "                    print(f\"Warning: Simple Agent at position {position} has an empty target tensor.\")\n",
    "                    continue\n",
    "                \n",
    "                simple_targets.append(simple_target.item())\n",
    "            \n",
    "            # Check if we have valid targets for all simple agents\n",
    "            if len(simple_targets) != len(simple_agents):\n",
    "                print(\"Skipping this sample due to mismatched number of simple targets\")\n",
    "                continue\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.tensor(simple_targets + [complex_target], dtype=torch.long)\n",
    "            print(f\"All Targets shape: {all_targets.shape}\")\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for position, pred in zip(simple_agents, simple_predictions):\n",
    "                probabilities = torch.nn.functional.softmax(pred, dim=0)\n",
    "                predicted_class = torch.argmax(probabilities).item()\n",
    "                transformed_grid[position[0]][position[1]] = predicted_class\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(input_grid, simple_agents, complex_agent, device=device)\n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if average_validation_loss < best_loss:\n",
    "            best_loss = average_validation_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping: Validation loss did not improve for {} epochs.\".format(patience))\n",
    "                break\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')  # Prefix added here\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')  # Prefix added here\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, complex_agent, device='cuda'):\n",
    "    transformed = np.zeros_like(grid)  # Initialize with zeros\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        # Pad the local area if necessary\n",
    "        if len(local_area) != 9:\n",
    "            print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](local_area_tensor.unsqueeze(0)).cpu()\n",
    "        probabilities = torch.nn.functional.softmax(prediction, dim=1)\n",
    "        \n",
    "        # Log the probabilities for debugging\n",
    "        print(f\"Simple Agent at position {position} - Predicted Probabilities: {probabilities.squeeze().tolist()}\")\n",
    "        \n",
    "        # Get the predicted class (integer between 0 and 9)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "        transformed[position[0]][position[1]] = predicted_class\n",
    "    \n",
    "    complex_prediction = complex_agent(grid_tensor.view(-1).unsqueeze(0)).cpu()\n",
    "    complex_probabilities = torch.nn.functional.softmax(complex_prediction, dim=1)\n",
    "    \n",
    "    # Log the complex agent's probabilities for debugging\n",
    "    print(f\"Complex Agent - Predicted Probabilities: {complex_probabilities.squeeze().tolist()}\")\n",
    "    \n",
    "    # Get the predicted class (integer between 0 and 9)\n",
    "    complex_predicted_class = torch.argmax(complex_probabilities).item()\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "# Function to load ARC JSON data\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = np.array(task['input'])\n",
    "        output_grid = np.array(task['output'])\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using timestamp\n",
    "prefix = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Example: \"20231005_143000\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = np.array(inputs[i])\n",
    "        output_grid = np.array(outputs[i])\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        complex_agent = ComplexAgent(input_size=grid_size[0] * grid_size[1])\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        train_inputs = [torch.tensor(input_grid, dtype=torch.float32).to(device)]\n",
    "        train_outputs = [torch.tensor(output_grid, dtype=torch.long).to(device)]\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agents, complex_agent, train_inputs, train_outputs, epochs=100, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid, simple_agents, complex_agent, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71538aaf-97f9-4c44-b965-6faa7ae0e90d",
   "metadata": {},
   "source": [
    "Removing the ComplexAgent (wasn't doing anything useful) and increasing the number of simple agents to cover the entire grid (no gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650834b-2bff-4326-b7fe-45ea76ca6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    for i in range(0, grid_size[0], agent_scope - 1):  # Adjust step size to ensure overlap\n",
    "        for j in range(0, grid_size[1], agent_scope - 1):\n",
    "            if i + agent_scope <= grid_size[0] and j + agent_scope <= grid_size[1]:\n",
    "                agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agents, inputs, outputs, epochs=50, learning_rate=0.1, device='cuda', plot_dir=None):\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position in simple_agents:\n",
    "        model = simple_agent_models[position]\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                model = simple_agent_models[position]\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        transformed_grid = np.zeros_like(inputs[0].cpu().numpy())\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                model = simple_agent_models[position]\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agents:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for j, position in enumerate(simple_agents):\n",
    "                if combined_pred[j].argmax(dim=0).item() == 4:\n",
    "                    transformed_grid[position[0]][position[1]] = 4\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(input_grid, simple_agents, device=device)\n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](local_area_tensor.unsqueeze(0)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        if prediction == 4:\n",
    "            transformed[position[0]][position[1]] = 4\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "# Function to load ARC JSON data\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = np.array(task['input'])\n",
    "        output_grid = np.array(task['output'])\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using timestamp\n",
    "prefix = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Example: \"20231005_143000\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = np.array(inputs[i])\n",
    "        output_grid = np.array(outputs[i])\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        complex_agent = ComplexAgent(input_size=grid_size[0] * grid_size[1])\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        train_inputs = [torch.tensor(input_grid, dtype=torch.float32).to(device)]\n",
    "        train_outputs = [torch.tensor(output_grid, dtype=torch.long).to(device)]\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agents, train_inputs, train_outputs, epochs=50, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid, simple_agents, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117c8f6-8be7-4ec0-8dc8-4a67df45c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    for i in range(0, grid_size[0], agent_scope - 1):  # Adjust step size to ensure overlap\n",
    "        for j in range(0, grid_size[1], agent_scope - 1):\n",
    "            if i + agent_scope <= grid_size[0] and j + agent_scope <= grid_size[1]:\n",
    "                agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=10, learning_rate=0.001, device='cuda', plot_dir=None):\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        transformed_grid = np.zeros_like(inputs[0].cpu().numpy())\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                loss = criterion(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for j, position in enumerate(simple_agent_models):\n",
    "                if combined_pred[j].argmax(dim=0).item() == 4:\n",
    "                    transformed_grid[position[0]][position[1]] = 4\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(input_grid, simple_agent_models, device=device)\n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.00001 and average_validation_loss < 0.00001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = torch.tensor(transformed_grid, dtype=torch.float32).to(device)\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agent_models, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position, model in simple_agent_models.items():\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = model(local_area_tensor.unsqueeze(0)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        if prediction == 4:\n",
    "            transformed[position[0]][position[1]] = 4\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "# Function to load ARC JSON data\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = np.array(task['input'])\n",
    "        output_grid = np.array(task['output'])\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using timestamp\n",
    "prefix = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Example: \"20231005_143000\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = np.array(inputs[i])\n",
    "        output_grid = np.array(outputs[i])\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        train_inputs = [torch.tensor(input_grid, dtype=torch.float32).to(device)]\n",
    "        train_outputs = [torch.tensor(output_grid, dtype=torch.long).to(device)]\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=50, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid, simple_agent_models, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid)\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887f4eb-3376-4213-9334-2e2dc28dd560",
   "metadata": {},
   "source": [
    "working but there are still gaps between the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a12605-2dcf-4a69-b82d-fcc7fb4c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    for i in range(0, grid_size[0], agent_scope - 1):  # Adjust step size to ensure overlap\n",
    "        for j in range(0, grid_size[1], agent_scope - 1):\n",
    "            if i + agent_scope <= grid_size[0] and j + agent_scope <= grid_size[1]:\n",
    "                agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=50, learning_rate=0.001, device='cuda', plot_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        # Initialize transformed_grid with zeros for consistency\n",
    "        max_value = inputs[0].max().item()  # Convert tensor to scalar\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0])  # Use torch.rand_like for similar shape and dtype\n",
    "        \n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for j, position in enumerate(simple_agents):\n",
    "                if combined_pred[j].argmax(dim=0).item() == 4:\n",
    "                    transformed_grid_tensor[position[0]][position[1]] = max_value\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, device=device)\n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.00001 and average_validation_loss < 0.00001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)  # Ensure it's on the correct device before updating\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](local_area_tensor.unsqueeze(0)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        if prediction == 4:\n",
    "            transformed[position[0]][position[1]] = grid.max().item()\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(grid.cpu().numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        train_inputs = [input_grid.to(device)]\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(input_grid, prefix, plot_dir)\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=50, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b8f03-7214-4f57-84ac-4bdb82c0b70a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## fix the grid so all squares can be affected by agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52a8c3-3691-4d93-901e-9231298a0bca",
   "metadata": {},
   "source": [
    "all cells are changing and something is happening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f96b7-4edc-4599-ad3a-e3d610590add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=9):  # For a 3x3 grid area\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 18)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(18, 16)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(16, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)  # Softmax for multiple classes\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=30, learning_rate=0.0001, device='cuda', plot_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        # Initialize transformed_grid with zeros for consistency\n",
    "        max_value = inputs[0].max().item()  # Convert tensor to scalar\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0])  # Use torch.rand_like for similar shape and dtype\n",
    "        \n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for j, position in enumerate(simple_agents):\n",
    "                prediction = combined_pred[j].argmax(dim=0).item()\n",
    "                # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "                \n",
    "                transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, device=device)\n",
    "        \n",
    "        # Debug: Print the updated grid values\n",
    "        # print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.00001 and average_validation_loss < 0.00001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)  # Ensure it's on the correct device before updating\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](local_area_tensor.unsqueeze(0)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        ititial_grid = input_grid\n",
    "        \n",
    "        # train_inputs = [initial_grid]\n",
    "        train_inputs = [input_grid]\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=200, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6ae87-85a5-4fce-97e0-4027bff997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 10)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(10, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=30, learning_rate=0.00001, device='cuda', plot_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        # Initialize transformed_grid with zeros for consistency\n",
    "        max_value = inputs[0].max().item()  # Convert tensor to scalar\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0])  # Use torch.rand_like for similar shape and dtype\n",
    "        \n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for j, position in enumerate(simple_agents):\n",
    "                prediction = combined_pred[j].argmax(dim=0).item()\n",
    "                # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "                \n",
    "                transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, device=device)\n",
    "        \n",
    "        # Debug: Print the updated grid values\n",
    "        # print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.01 and average_validation_loss < 0.01:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)  # Ensure it's on the correct device before updating\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # Save only the grid plot without colorbar\n",
    "    fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    fig2.savefig(grid_plot_path)\n",
    "    print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {agent: SimpleAgent() for agent in simple_agents}\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        ititial_grid = input_grid\n",
    "        \n",
    "        # train_inputs = [initial_grid]\n",
    "        train_inputs = [input_grid]\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=200, device=device, plot_dir=plot_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cd018-248f-41cf-bb7e-36dbb9b6e13f",
   "metadata": {},
   "source": [
    "Working!   ...as the fanciest random grid generator ever.  That validation step is suspicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781ea76-b837-4720-8301-a89d2dd97aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=4, learning_rate=0.01, device='cuda', plot_dir=None, model_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        # Initialize transformed_grid with zeros for consistency\n",
    "        max_value = inputs[0].max().item()  # Convert tensor to scalar\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0])  # Use torch.rand_like for similar shape and dtype\n",
    "        \n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                    # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction (validation phase)\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate validation loss for each prediction separately\n",
    "            total_validation_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_validation_loss_this_sample += loss.item()\n",
    "            \n",
    "            validation_loss += total_validation_loss_this_sample\n",
    "            \n",
    "            # Update transformed grid based on predictions (if needed)\n",
    "            for j, position in enumerate(simple_agents):\n",
    "                prediction = combined_pred[j].argmax(dim=0).item()\n",
    "                # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "                \n",
    "                transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, device=device)\n",
    "        \n",
    "        # Debug: Print the updated grid values\n",
    "        # print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.001 and average_validation_loss < 0.001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)  # Ensure it's on the correct device before updating\n",
    "        clear_output(wait=True)  # Clear the output before logging new information\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "    \n",
    "    # Save the model after training\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Saved model at position {position} to {model_path}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # ******** Save only the grid plot without colorbar\n",
    "    # fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    # cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    # ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    # fig2.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    # plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    # initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory and model directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                model = SimpleAgent()\n",
    "            simple_agent_models[position] = model\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        ititial_grid = input_grid\n",
    "        print(f\"\\nInitial Grid:\\n{ititial_grid}\")\n",
    "        \n",
    "        # train_inputs = [initial_grid]\n",
    "        train_inputs = [input_grid.to(device)]\n",
    "        print(f\"\\nInput Grid:\\n{train_inputs}\")\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        print(f\"\\nOutput Grid:\\n{train_outputs}\")\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        # save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        # pause for debugging\n",
    "        input(\"Press Enter to continue...\")\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=500, device=device, plot_dir=plot_dir, model_dir=model_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        # pause for debugging\n",
    "        input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8538f9b-3ef4-461d-97b3-c9ffeccadf01",
   "metadata": {},
   "source": [
    "# 3x3 SimpleAgents Working on ARC Puzzles POC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f61a75-8f41-48d8-a909-ad25814a9243",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.1 Basically Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0402a6-039d-4ea7-84cd-3c5291751aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=4, learning_rate=0.1, device='cuda', plot_dir=None, model_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        # Initialize transformed_grid with zeros for consistency\n",
    "        max_value = inputs[0].max().item()  # Convert tensor to scalar\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0])  # Use torch.rand_like for similar shape and dtype\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "                simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "                \n",
    "                # Collect predictions from simple agents\n",
    "                for position, model in simple_agent_models.items():\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(x.size(0), position[0] + 3)\n",
    "                    y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                    local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                    \n",
    "                    if len(local_x) != 9:\n",
    "                        local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                    \n",
    "                    # Add epoch to the input\n",
    "                    local_x_with_epoch = torch.cat((local_x, torch.tensor([epoch]).float().to(device)), dim=0)\n",
    "                    \n",
    "                    # Forward pass for the current simple agent\n",
    "                    prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                    \n",
    "                    # Append the prediction to the list (ensure it's on CPU)\n",
    "                    simple_predictions.append(prediction.squeeze().cpu())\n",
    "                \n",
    "                combined_pred = torch.stack(simple_predictions)\n",
    "                \n",
    "                # Prepare target values for each prediction (validation phase)\n",
    "                y_flat = y.flatten().long().to(device)\n",
    "                simple_targets = []\n",
    "                \n",
    "                for position in simple_agent_models:\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(x.size(0), position[0] + 3)\n",
    "                    y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                    local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                    \n",
    "                    if len(local_y) != 9:\n",
    "                        local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                    \n",
    "                    # Correct the dimension for argmax\n",
    "                    simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "                \n",
    "                # Stack all targets and ensure they match the batch size of combined_pred\n",
    "                all_targets = torch.stack(simple_targets)\n",
    "                \n",
    "                # Calculate validation loss for each prediction separately\n",
    "                total_validation_loss_this_sample = 0\n",
    "                for pred, target in zip(combined_pred, all_targets):\n",
    "                    # Convert target to float before calculating loss\n",
    "                    target_float = target.float()\n",
    "                    loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                    total_validation_loss_this_sample += loss.item()\n",
    "                \n",
    "                validation_loss += total_validation_loss_this_sample\n",
    "                \n",
    "                # Update transformed grid based on predictions (if needed)\n",
    "                for j, position in enumerate(simple_agents):\n",
    "                    prediction = combined_pred[j].argmax(dim=0).item()\n",
    "                    \n",
    "                    transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        # print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, epoch=epoch, device=device)\n",
    "        \n",
    "        # Debug: Print the updated grid values\n",
    "        # print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.001 and average_validation_loss < 0.001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)  # Ensure it's on the correct device before updating\n",
    "        clear_output(wait=True)  # Clear the output before logging new information then display last epoch info\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "    \n",
    "    # Save the model after training\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Saved model at position {position} to {model_path}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # ******** Save only the grid plot without colorbar\n",
    "    # fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    # cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    # ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    # fig2.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    # plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    # initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    initial_grid = grid\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory and model directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                model = SimpleAgent()\n",
    "            simple_agent_models[position] = model\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        initial_grid = input_grid\n",
    "        print(f\"\\nInitial Grid:\\n{initial_grid}\")\n",
    "        \n",
    "        train_inputs = [initial_grid]\n",
    "        # train_inputs = [input_grid.to(device)]\n",
    "        print(f\"\\nInput Grid:\\n{train_inputs}\")\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        print(f\"\\nOutput Grid:\\n{train_outputs}\")\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=1000, device=device, plot_dir=plot_dir, model_dir=model_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, epoch=0, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2e3f9-76da-40b0-a258-a038ecdfdfd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.2 Normalized epoch input and step through network for vaidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb3e11-f158-4f28-8484-1bf4b0cdf3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=4, learning_rate=0.1, device='cuda', plot_dir=None, model_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Normalize the epoch\n",
    "                normalized_epoch = float(epoch) / epochs\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase (same as training phase)\n",
    "        validation_loss = 0\n",
    "        transformed_grid_tensor = torch.clone(inputs[0]).to(device)  # Start with the input grid\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(10):  # Iterate the network for 10 steps\n",
    "                simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "                \n",
    "                # Collect predictions from simple agents\n",
    "                for position, model in simple_agent_models.items():\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(transformed_grid_tensor.size(0), position[0] + 3)\n",
    "                    y_end = min(transformed_grid_tensor.size(1), position[1] + 3)\n",
    "\n",
    "                    local_x = transformed_grid_tensor[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                    \n",
    "                    if len(local_x) != 9:\n",
    "                        local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                    \n",
    "                    # Normalize the epoch\n",
    "                    normalized_epoch = float(epoch) / epochs\n",
    "                    \n",
    "                    # Add epoch to the input\n",
    "                    local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "                    \n",
    "                    # Forward pass for the current simple agent\n",
    "                    prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                    \n",
    "                    # Append the prediction to the list (ensure it's on CPU)\n",
    "                    simple_predictions.append(prediction.squeeze().cpu())\n",
    "                \n",
    "                combined_pred = torch.stack(simple_predictions)\n",
    "                \n",
    "                # Update transformed grid based on predictions (if needed)\n",
    "                for j, position in enumerate(simple_agents):\n",
    "                    prediction = combined_pred[j].argmax(dim=0).item()\n",
    "                    \n",
    "                    transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "        # print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, epoch=epoch, device=device)\n",
    "        \n",
    "        # Debug: Print the updated grid values\n",
    "        # print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        # Check if both training and validation loss are below the threshold\n",
    "        if average_loss < 0.001 and average_validation_loss < 0.001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)  # Ensure it's on the correct device before updating\n",
    "        clear_output(wait=True)  # Clear the output before logging new information then display last epoch info\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "    \n",
    "    # Save the model after training\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Saved model at position {position} to {model_path}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # ******** Save only the grid plot without colorbar\n",
    "    # fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    # cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    # ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    # fig2.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    # plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    # initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    initial_grid = grid\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory and model directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                model = SimpleAgent()\n",
    "            simple_agent_models[position] = model\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        initial_grid = input_grid\n",
    "        print(f\"\\nInitial Grid:\\n{initial_grid}\")\n",
    "        \n",
    "        train_inputs = [initial_grid]\n",
    "        # train_inputs = [input_grid.to(device)]\n",
    "        print(f\"\\nInput Grid:\\n{train_inputs}\")\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        print(f\"\\nOutput Grid:\\n{train_outputs}\")\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=1000, device=device, plot_dir=plot_dir, model_dir=model_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, epoch=0, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3474697-9847-419d-bf6d-68fbd894feb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.3 Added cross entropy loss and accumulation during validation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd28719-ee9a-4bee-9629-f2946eac9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=4, learning_rate=0.0005, device='cuda', plot_dir=None, model_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Normalize the epoch\n",
    "                normalized_epoch = float(epoch) / epochs\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase\n",
    "        validation_loss = 0\n",
    "\n",
    "        # Initialize transformed grid with zeros for consistency\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0], dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "                simple_predictions = []\n",
    "\n",
    "                # Collect predictions from simple agents\n",
    "                for position, model in simple_agent_models.items():\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(x.size(0), position[0] + 3)\n",
    "                    y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                    local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "\n",
    "                    if len(local_x) != 9:\n",
    "                        local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "\n",
    "                    # Normalize epoch\n",
    "                    normalized_epoch = float(epoch) / epochs\n",
    "\n",
    "                    # Add epoch to the input\n",
    "                    local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "\n",
    "                    # Forward pass for the current simple agent\n",
    "                    prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                    \n",
    "                    # Append the prediction (logits) to the list (ensure it's on CPU)\n",
    "                    simple_predictions.append(prediction.squeeze().cpu())\n",
    "\n",
    "                combined_pred = torch.stack(simple_predictions)\n",
    "\n",
    "                # Prepare target values for each prediction (validation phase)\n",
    "                y_flat = y.flatten().long().to(device)\n",
    "                simple_targets = []\n",
    "\n",
    "                for position in simple_agent_models:\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(y.size(0), position[0] + 3)\n",
    "                    y_end = min(y.size(1), position[1] + 3)\n",
    "\n",
    "                    local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "\n",
    "                    if len(local_y) != 9:\n",
    "                        local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "\n",
    "                    # Convert to long and append the target\n",
    "                    simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "\n",
    "                all_targets = torch.stack(simple_targets)\n",
    "\n",
    "                # Calculate validation loss for each prediction separately\n",
    "                total_validation_loss_this_sample = 0\n",
    "\n",
    "                for pred, target in zip(combined_pred, all_targets):\n",
    "                    if pred.numel() == 0 or target.numel() == 0:\n",
    "                        raise ValueError(f\"Zero-sized tensor encountered. pred shape: {pred.shape}, target shape: {target.shape}\")\n",
    "                    \n",
    "                    # Ensure the target is a LongTensor for CrossEntropyLoss\n",
    "                    loss = criterion(pred.unsqueeze(0), target.long().unsqueeze(0))\n",
    "                    total_validation_loss_this_sample += loss.item()\n",
    "\n",
    "                validation_loss += total_validation_loss_this_sample\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "\n",
    "        # Update transformed grid based on predictions (if needed)\n",
    "        for j, position in enumerate(simple_agents):\n",
    "            prediction = combined_pred[j].argmax(dim=0).item()\n",
    "            transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "        \n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, epoch=epoch, device=device)\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        if average_loss < 0.000001 and average_validation_loss < 0.000001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "    \n",
    "    # Save the model after training\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Saved model at position {position} to {model_path}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # ******** Save only the grid plot without colorbar\n",
    "    # fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    # cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    # ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    # fig2.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    # plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    # initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    initial_grid = grid\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='viridis', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory and model directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                model = SimpleAgent()\n",
    "            simple_agent_models[position] = model\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        initial_grid = input_grid\n",
    "        print(f\"\\nInitial Grid:\\n{initial_grid}\")\n",
    "        \n",
    "        train_inputs = [initial_grid]\n",
    "        # train_inputs = [input_grid.to(device)]\n",
    "        print(f\"\\nInput Grid:\\n{train_inputs}\")\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        print(f\"\\nOutput Grid:\\n{train_outputs}\")\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=1000, device=device, plot_dir=plot_dir, model_dir=model_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, epoch=0, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        # pause for debugging\n",
    "        input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46c9c8-8fca-462c-b4df-23c25d96b983",
   "metadata": {},
   "source": [
    "## 0.4 Loss decreses with improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00195359-da8c-4b04-968d-0e46542ef7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|  | 672/700 [12:08:32<30:49, 66.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Grid after Epoch 672:\n",
      "[[0. 0. 0. 3. 9. 0. 3. 0. 0. 0. 3. 2. 6. 5. 5. 4. 1. 4. 8. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 4. 9. 0. 0. 2. 0. 0. 5. 5. 7. 1. 0. 2. 2.]\n",
      " [3. 0. 0. 7. 0. 4. 0. 0. 0. 7. 1. 0. 9. 3. 0. 7. 5. 9. 7. 2.]\n",
      " [0. 0. 0. 8. 0. 1. 3. 5. 0. 0. 3. 3. 0. 7. 7. 6. 1. 2. 3. 2.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 4. 0. 0. 7. 7. 0. 1. 0. 9. 0. 8. 4.]\n",
      " [2. 5. 0. 0. 0. 3. 0. 0. 0. 0. 6. 2. 2. 3. 4. 0. 6. 2. 2. 2.]\n",
      " [3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 3. 8. 4. 1. 7. 7. 1. 2. 0. 7.]\n",
      " [0. 0. 1. 4. 0. 0. 0. 0. 0. 5. 0. 2. 9. 8. 7. 9. 2. 7. 0. 9.]\n",
      " [0. 0. 8. 0. 0. 0. 0. 1. 0. 4. 8. 6. 9. 0. 3. 0. 7. 4. 9. 9.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 9. 9. 1. 5. 5. 6. 0. 6. 9. 5. 2. 3. 7.]\n",
      " [3. 8. 4. 8. 0. 2. 2. 3. 4. 0. 5. 7. 1. 3. 2. 2. 8. 8. 0. 6.]\n",
      " [0. 8. 7. 7. 1. 3. 7. 7. 8. 2. 1. 9. 5. 5. 7. 2. 5. 5. 4. 3.]\n",
      " [2. 4. 6. 4. 0. 4. 2. 2. 7. 1. 8. 6. 9. 6. 3. 0. 4. 9. 2. 8.]\n",
      " [3. 0. 5. 8. 4. 9. 9. 8. 4. 3. 0. 2. 9. 4. 0. 9. 5. 4. 7. 6.]\n",
      " [5. 8. 1. 2. 0. 0. 0. 0. 0. 9. 8. 7. 0. 6. 6. 0. 3. 1. 6. 6.]\n",
      " [6. 7. 0. 5. 0. 8. 8. 8. 0. 0. 1. 7. 3. 7. 0. 0. 0. 0. 1. 6.]\n",
      " [0. 0. 2. 8. 9. 6. 6. 2. 1. 0. 2. 6. 8. 2. 1. 1. 0. 0. 3. 4.]\n",
      " [5. 5. 4. 8. 6. 3. 0. 3. 3. 3. 1. 5. 5. 4. 6. 8. 4. 6. 5. 0.]\n",
      " [1. 7. 9. 8. 3. 2. 6. 7. 6. 9. 9. 3. 8. 0. 3. 7. 1. 7. 3. 0.]\n",
      " [9. 8. 0. 1. 2. 0. 8. 2. 8. 3. 5. 5. 0. 2. 6. 0. 0. 7. 6. 5.]]\n",
      "Epoch 672, Training Loss: 7434.0269, Validation Loss: 7434.0267\n",
      "\n",
      "New Learning Rate:0.001\n",
      "Epoch 673/700\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape before concatenation: {x.shape}\")\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        # print(f\"Input shape after concatenation: {x.shape}\")\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "# ************************ set initial learning rate here\n",
    "def train_agents(fig, ax1, ax2, simple_agent_models, inputs, outputs, epochs=4, learning_rate=0.01, device='cuda', plot_dir=None, model_dir=None):\n",
    "    criterion = nn.MSELoss()  # Use MSE Loss\n",
    "    \n",
    "    print(\"Moving models to the specified device...\")\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model.to(device)\n",
    "        print(f\"Simple Agent at position {position} moved to {device}\")\n",
    "\n",
    "    # Flatten list of lists into a single list of parameters\n",
    "    params_to_optimize = [param for _, model in simple_agent_models.items() for param in model.parameters()]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    losses = []  # Initialize an empty list to store all epoch losses\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        num_samples = len(inputs)\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            simple_predictions = []  # Initialize this list at the start of each iteration\n",
    "            \n",
    "            # Collect predictions from simple agents\n",
    "            for position, model in simple_agent_models.items():\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_x) != 9:\n",
    "                     # print(f\"Padded local_x shape: {local_x.shape}\")\n",
    "                    local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "                \n",
    "                # Normalize the epoch\n",
    "                normalized_epoch = float(epoch) / epochs\n",
    "                \n",
    "                # Add epoch to the input\n",
    "                local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "                \n",
    "                # Forward pass for the current simple agent\n",
    "                prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                # print(f\"Simple Agent at position {position} prediction shape: {prediction.shape}\")\n",
    "                \n",
    "                # Append the prediction to the list (ensure it's on CPU)\n",
    "                simple_predictions.append(prediction.squeeze().cpu())\n",
    "            \n",
    "            combined_pred = torch.stack(simple_predictions)\n",
    "            \n",
    "            # Prepare target values for each prediction\n",
    "            y_flat = y.flatten().long().to(device)\n",
    "            simple_targets = []\n",
    "            \n",
    "            for position in simple_agent_models:\n",
    "                x_start = max(0, position[0])\n",
    "                y_start = max(0, position[1])\n",
    "                x_end = min(x.size(0), position[0] + 3)\n",
    "                y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "                \n",
    "                if len(local_y) != 9:\n",
    "                    # print(f\"Padded local_y shape: {local_y.shape}\")\n",
    "                    local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "                \n",
    "                # Correct the dimension for argmax\n",
    "                simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "            \n",
    "            # Stack all targets and ensure they match the batch size of combined_pred\n",
    "            all_targets = torch.stack(simple_targets)\n",
    "            \n",
    "            # Calculate loss for each prediction separately\n",
    "            total_loss_this_sample = 0\n",
    "            for pred, target in zip(combined_pred, all_targets):\n",
    "                # Convert target to float before calculating loss\n",
    "                target_float = target.float()\n",
    "                loss = criterion(pred.unsqueeze(0), target_float.unsqueeze(0))\n",
    "                total_loss_this_sample += loss.item()\n",
    "                loss.backward(retain_graph=True)  # Retain graph to allow backpropagation through all agents\n",
    "            \n",
    "            total_loss += total_loss_this_sample\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = total_loss / num_samples\n",
    "        losses.append(average_loss)  # Append the current epoch's average loss\n",
    "        \n",
    "        # Validation phase\n",
    "        validation_loss = 0\n",
    "\n",
    "        # Initialize transformed grid with zeros for consistency\n",
    "        transformed_grid_tensor = torch.zeros_like(inputs[0], dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(zip(inputs, outputs)):\n",
    "                simple_predictions = []\n",
    "\n",
    "                # Collect predictions from simple agents\n",
    "                for position, model in simple_agent_models.items():\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(x.size(0), position[0] + 3)\n",
    "                    y_end = min(x.size(1), position[1] + 3)\n",
    "\n",
    "                    local_x = x[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "\n",
    "                    if len(local_x) != 9:\n",
    "                        local_x = torch.nn.functional.pad(local_x, (0, 9 - len(local_x)))\n",
    "\n",
    "                    # Normalize epoch\n",
    "                    normalized_epoch = float(epoch) / epochs\n",
    "\n",
    "                    # Add epoch to the input\n",
    "                    local_x_with_epoch = torch.cat((local_x, torch.tensor([normalized_epoch]).float().to(device)), dim=0)\n",
    "\n",
    "                    # Forward pass for the current simple agent\n",
    "                    prediction = model(local_x_with_epoch.unsqueeze(0).to(device))\n",
    "                    \n",
    "                    # Append the prediction (logits) to the list (ensure it's on CPU)\n",
    "                    simple_predictions.append(prediction.squeeze().cpu())\n",
    "\n",
    "                combined_pred = torch.stack(simple_predictions)\n",
    "\n",
    "                # Prepare target values for each prediction (validation phase)\n",
    "                y_flat = y.flatten().long().to(device)\n",
    "                simple_targets = []\n",
    "\n",
    "                for position in simple_agent_models:\n",
    "                    x_start = max(0, position[0])\n",
    "                    y_start = max(0, position[1])\n",
    "                    x_end = min(y.size(0), position[0] + 3)\n",
    "                    y_end = min(y.size(1), position[1] + 3)\n",
    "\n",
    "                    local_y = y[x_start:x_end, y_start:y_end].flatten().to(device)\n",
    "\n",
    "                    if len(local_y) != 9:\n",
    "                        local_y = torch.nn.functional.pad(local_y, (0, 9 - len(local_y)))\n",
    "\n",
    "                    # Convert to long and append the target\n",
    "                    simple_targets.append(local_y.argmax(dim=0).cpu())\n",
    "\n",
    "                all_targets = torch.stack(simple_targets)\n",
    "\n",
    "                # Calculate validation loss for each prediction separately\n",
    "                total_validation_loss_this_sample = 0\n",
    "\n",
    "                for pred, target in zip(combined_pred, all_targets):\n",
    "                    if pred.numel() == 0 or target.numel() == 0:\n",
    "                        raise ValueError(f\"Zero-sized tensor encountered. pred shape: {pred.shape}, target shape: {target.shape}\")\n",
    "                    \n",
    "                    # Ensure the target is a LongTensor for CrossEntropyLoss\n",
    "                    loss = criterion(pred.unsqueeze(0), target.long().unsqueeze(0))\n",
    "                    total_validation_loss_this_sample += loss.item()\n",
    "\n",
    "                validation_loss += total_validation_loss_this_sample\n",
    "\n",
    "        average_validation_loss = validation_loss / num_samples\n",
    "\n",
    "        # Update transformed grid based on predictions (if needed)\n",
    "        for j, position in enumerate(simple_agents):\n",
    "            prediction = combined_pred[j].argmax(dim=0).item()\n",
    "            transformed_grid_tensor[position[0]][position[1]] = prediction\n",
    "        \n",
    "        # Update and display the grid visualization\n",
    "        transformed = transform_grid(inputs[0].cpu(), simple_agents, epoch=epoch, device=device)\n",
    "        \n",
    "        update_plots(fig, ax1, ax2, epoch + 1, losses, transformed, plot_dir)\n",
    "\n",
    "        if average_loss < 0.000001 and average_validation_loss < 0.000001:\n",
    "            print(\"Training complete: Both training and validation loss are below 0.00001.\")\n",
    "            break\n",
    "\n",
    "        # ***********  Adjust the learning rate as loss decreases\n",
    "        initial_lr = optimizer.param_groups[0]['lr']\n",
    "        max_epoch = epochs\n",
    "        k = 0.5  # higher value will make transition to lower rate toward end of training steeper (0.1 to 0.9)\n",
    "        min_lr = 0.001  # Minimum learning rate\n",
    "        new_lr = initial_lr\n",
    "        decay_factor = 0\n",
    "        if epoch > 0 and losses[-1] < losses[-2]:\n",
    "            # Calculate the decay factor using a sigmoid function\n",
    "            decay_factor = 1 / (1 + math.exp(-k * (epoch - max_epoch / 2)))\n",
    "            new_lr = initial_lr * (1 - decay_factor)\n",
    "            # Ensure the learning rate does not decrease below the minimum threshold\n",
    "            if new_lr > min_lr:\n",
    "                optimizer.param_groups[0]['lr'] = new_lr\n",
    "                print(f\"Reducing learning rate from {initial_lr} to {new_lr}\")\n",
    "            else:\n",
    "                print(f\"Learning rate would have decreased to {new_lr}, but it has been set to the minimum threshold of {min_lr}.\")\n",
    "                optimizer.param_groups[0]['lr'] = min_lr\n",
    "                new_lr = min_lr\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "\n",
    "        # Update the grid for the next epoch\n",
    "        inputs[0] = transformed_grid_tensor.to(device)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Updated Grid after Epoch {epoch + 1}:\\n{transformed}\")\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {average_loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "        print(f\"\\nNew Learning Rate:{new_lr}\")\n",
    "    \n",
    "    # Save the model after training\n",
    "    for position, model in simple_agent_models.items():\n",
    "        model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Saved model at position {position} to {model_path}\")\n",
    "\n",
    "def update_plots(fig, ax1, ax2, epoch, losses, transformed, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    # Update the loss plot\n",
    "    ax1.plot(range(1, len(losses) + 1), losses, marker='o', color='blue')\n",
    "    ax1.set_title(f'Loss Over Epochs (Epoch {epoch})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Ensure transformed is a NumPy array before passing to imshow\n",
    "    if isinstance(transformed, torch.Tensor):\n",
    "        transformed = transformed.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax2.imshow(transformed, cmap='inferno', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax2.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    \n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    loss_plot_path = os.path.join(plot_dir, f'{prefix}_loss_epoch_{epoch}.png')\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(loss_plot_path)\n",
    "    print(f\"Saved loss plot for epoch {epoch} to {loss_plot_path}\")\n",
    "    \n",
    "    # ******** Save only the grid plot without colorbar\n",
    "    # fig2, ax3 = plt.subplots(figsize=(7, 6))\n",
    "    # cax2 = ax3.imshow(transformed, cmap='viridis', interpolation='nearest')\n",
    "    # ax3.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "    # fig2.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "    # plt.close(fig2)\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.array(grid)  # Initialize with input grid\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            # print(f\"Padded local_area shape: {local_area.shape}\")\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        prediction = simple_agent_models[position](torch.cat((local_area_tensor.unsqueeze(0), torch.tensor([epoch]).float().unsqueeze(0).to(device)), dim=1)).cpu().argmax(dim=1).item()  # Move back to CPU for numpy conversion\n",
    "        \n",
    "        # print(f\"Agent at position {position} predicted: {prediction}\")\n",
    "        \n",
    "        transformed[position[0]][position[1]] = prediction\n",
    "            \n",
    "    return transformed\n",
    "\n",
    "def save_initial_grid(grid, prefix, plot_dir):\n",
    "    # Generate a random grid with values between 0 and 9\n",
    "    # initial_grid = torch.randint(10, size=grid.shape).float()\n",
    "    initial_grid = grid\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    cax = ax.imshow(initial_grid.numpy(), cmap='inferno', interpolation='nearest')\n",
    "    ax.set_title(f'Initial Grid (Prefix: {prefix})')\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    initial_grid_plot_path = os.path.join(plot_dir, f'{prefix}_initial_grid.png')\n",
    "    plt.savefig(initial_grid_plot_path)\n",
    "    print(f\"Saved initial grid plot to {initial_grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the plot directory and model directory\n",
    "plot_dir = '/home/xaqmusic/plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "loss_plot, = ax1.plot([], [], marker='o')\n",
    "ax1.set_title('Loss Over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Creating agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                model = SimpleAgent()\n",
    "            simple_agent_models[position] = model\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # **** Generate a random initial grid with values between 0 and 9\n",
    "        # initial_grid = torch.randint(10, size=grid_size).float().to(device)\n",
    "        # **** or just the input grid to start\n",
    "        initial_grid = input_grid\n",
    "        print(f\"\\nInitial Grid:\\n{initial_grid}\")\n",
    "        \n",
    "        train_inputs = [initial_grid]\n",
    "        # train_inputs = [input_grid.to(device)]\n",
    "        print(f\"\\nInput Grid:\\n{train_inputs}\")\n",
    "        train_outputs = [output_grid.to(device)]\n",
    "        print(f\"\\nOutput Grid:\\n{train_outputs}\")\n",
    "        \n",
    "        # Save the initial grid before training\n",
    "        save_initial_grid(initial_grid.cpu(), prefix, plot_dir)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        \n",
    "        print(\"Training Agents...\")\n",
    "        train_agents(fig, ax1, ax2, simple_agent_models, train_inputs, train_outputs, epochs=700, device=device, plot_dir=plot_dir, model_dir=model_dir)\n",
    "        \n",
    "        print(\"\\nTransforming Grid...\")\n",
    "        transformed = transform_grid(input_grid.cpu(), simple_agents, epoch=0, device=device)\n",
    "        print(\"\\nInput Grid:\")\n",
    "        print(input_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Desired):\")\n",
    "        print(output_grid.cpu().numpy())\n",
    "        print(\"\\nOutput Grid after Transformation (Model's Prediction):\")\n",
    "        print(transformed)\n",
    "        # pause for debugging\n",
    "        # input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d55ca-ef3c-4339-9098-e4899ac71557",
   "metadata": {},
   "source": [
    "# Inference Runner for Current Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858235b2-4e43-4670-b1ab-f708ca1ccdd0",
   "metadata": {},
   "source": [
    "If you change the model definition (layers etc) during training, be sure it is also changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3c4e2-53ed-4213-9918-d8efcdd845cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure the correct backend is used for interactive plots\n",
    "import matplotlib\n",
    "matplotlib.use('inline')\n",
    "%matplotlib inline\n",
    "\n",
    "class SimpleAgent(nn.Module):\n",
    "    def __init__(self, input_size=18):  # Updated to handle concatenated input size of 18\n",
    "        super(SimpleAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)  # First hidden layer with larger capacity for the epoch input\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(36, 36)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(36, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.cat((x[:, :-1], x[:, -1].unsqueeze(1).repeat(1, 9)), dim=1)  # Repeat the epoch value to match grid input\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "def distribute_agents(grid_size, agent_scope=3):\n",
    "    agents = []\n",
    "    step_size = 1  # Place an agent at every cell\n",
    "    for i in range(0, grid_size[0], step_size):  \n",
    "        for j in range(0, grid_size[1], step_size):\n",
    "            agents.append((i, j))  # Record agent positions\n",
    "    return agents\n",
    "\n",
    "def transform_grid(grid, simple_agents, epoch, device='cuda'):\n",
    "    transformed = np.zeros_like(grid)  # Initialize with zeros\n",
    "    \n",
    "    # Convert grid to tensor and move it to the specified device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    for position in simple_agents:\n",
    "        x_start = max(0, position[0])\n",
    "        y_start = max(0, position[1])\n",
    "        x_end = min(len(transformed), position[0] + 3)\n",
    "        y_end = min(len(transformed[0]), position[1] + 3)\n",
    "\n",
    "        local_area = grid[x_start:x_end, y_start:y_end].flatten()\n",
    "        \n",
    "        if len(local_area) != 9:\n",
    "            local_area = np.pad(local_area, (0, 9 - len(local_area)), 'constant')\n",
    "        \n",
    "        # Convert local_area to tensor and move to device\n",
    "        local_area_tensor = torch.tensor(local_area, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Create the input for the model\n",
    "        epoch_tensor = torch.tensor([epoch], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        input_to_model = torch.cat((local_area_tensor.unsqueeze(0), epoch_tensor), dim=1)\n",
    "        \n",
    "        # Forward pass for the current simple agent if it exists\n",
    "        if position in simple_agent_models:\n",
    "            with torch.no_grad():  # Disable gradient computation during inference\n",
    "                prediction = simple_agent_models[position](input_to_model.to(device)).argmax(dim=1).item()  # Ensure input is on device\n",
    "            \n",
    "            transformed[position[0]][position[1]] = prediction\n",
    "        else:\n",
    "            print(f\"Warning: No model found for agent at position {position}. Skipping.\")\n",
    "            \n",
    "    return torch.tensor(transformed, dtype=torch.float32).to(device)\n",
    "\n",
    "def update_plots_inference(fig, ax1, epoch, current_grid, plot_dir):\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "\n",
    "    # Move the tensor to CPU and then convert it to a numpy array\n",
    "    current_grid_cpu = current_grid.cpu().numpy()\n",
    "    \n",
    "    # Update the grid visualization\n",
    "    cax = ax1.imshow(current_grid_cpu, cmap='viridis', interpolation='nearest')  # Convert tensor to numpy array\n",
    "    ax1.set_title(f'Grid Transformation (Epoch {epoch})')\n",
    "\n",
    "    # Save the plot to a file with a unique name based on the epoch number with linux timestamp\n",
    "    prefix = str(int(datetime.now().timestamp()))\n",
    "    grid_plot_path = os.path.join(plot_dir, f'{prefix}_grid_epoch_{epoch}.png')\n",
    "    \n",
    "    fig.savefig(grid_plot_path)\n",
    "    # print(f\"Saved grid plot for epoch {epoch} to {grid_plot_path}\")\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to load ARC JSON data and convert to tensors\n",
    "def load_arc_data(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for task in data['train']:\n",
    "        input_grid = torch.tensor(task['input'], dtype=torch.float32)\n",
    "        output_grid = torch.tensor(task['output'], dtype=torch.float32)\n",
    "        inputs.append(input_grid)\n",
    "        outputs.append(output_grid)\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Define the inference plot directory and model directory\n",
    "inf_plot_dir = '/home/xaqmusic/inf_plots'\n",
    "model_dir = '/home/xaqmusic/models'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(inf_plot_dir, exist_ok=True)\n",
    "\n",
    "# Generate a unique prefix for this run using Unix time (epoch seconds since 1970)\n",
    "prefix = str(int(datetime.now().timestamp()))  # Example: \"1693425180\"\n",
    "\n",
    "# Initialize plots at the beginning of your script\n",
    "fig_inference, ax_inference = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = '/home/xaqmusic/ARC-AGI/data/training/00d62c1b.json'\n",
    "    \n",
    "    # Load ARC JSON data and convert to tensors\n",
    "    inputs, outputs = load_arc_data(json_file)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input_grid = inputs[i]\n",
    "        output_grid = outputs[i]\n",
    "        \n",
    "        grid_size = input_grid.shape\n",
    "        \n",
    "        simple_agents = distribute_agents(grid_size)\n",
    "        \n",
    "        print(\"Loading agent models...\")\n",
    "        num_simple_agents = len(simple_agents)\n",
    "        global simple_agent_models\n",
    "        simple_agent_models = {}\n",
    "        for position in simple_agents:\n",
    "            model_path = os.path.join(model_dir, f'simple_agent_{position[0]}_{position[1]}.pth')\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                model = SimpleAgent()\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "                model.eval()  # Set the model to evaluation mode\n",
    "                simple_agent_models[position] = model.to(device)  # Ensure the model is on the correct device\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Initialize the grid for inference with the input grid\n",
    "        current_grid = input_grid.clone().to(device)\n",
    "        \n",
    "        print(\"Running Inference...\")\n",
    "        for epoch in tqdm(range(100), desc=\"Inference\", leave=False):\n",
    "            current_grid = transform_grid(current_grid.cpu(), simple_agents, epoch=epoch, device=device)\n",
    "            update_plots_inference(fig_inference, ax_inference, epoch + 1, current_grid, inf_plot_dir)\n",
    "            clear_output(wait=True)\n",
    "            # print(current_grid)\n",
    "        print(\"\\nFinal Grid after Inference:\")\n",
    "        print(current_grid.cpu().numpy())\n",
    "        input('Press Enter to Continue to Next Grid')\n",
    "\n",
    "# Close the inference figure to free up memory\n",
    "plt.close(fig_inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780a934-e220-4166-a7bf-70b5933d8d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
